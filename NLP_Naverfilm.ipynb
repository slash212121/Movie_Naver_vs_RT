{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_Naverfilm","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyMkDslBrgp2vrjc6Vu+VtGq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9ruegfRYusDw","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g3tsBTGJuydO","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import urllib.request\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import re\n","!pip install konlpy\n","from konlpy.tag import Okt\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import numpy as np\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gcq5oUgZvJW6","colab_type":"code","colab":{}},"source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fML90YfXvlPa","colab_type":"code","colab":{}},"source":["train_data = pd.read_table('ratings_train.txt')\n","test_data = pd.read_table('ratings_test.txt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V4QLaz-lvvzT","colab_type":"code","colab":{}},"source":["train_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Lpq6CoUvxtw","colab_type":"code","colab":{}},"source":["test_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ljATpfxHv0aM","colab_type":"code","colab":{}},"source":["print('훈련용 리뷰 개수 :',len(train_data))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dW4XTxDlwGzI","colab_type":"code","colab":{}},"source":["print('테스트용 리뷰 개수 :',len(test_data))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DPtwgtsVwN-t","colab_type":"code","colab":{}},"source":["train_data['document'].nunique(), train_data['label'].nunique()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OTlg8TQsxPy5","colab_type":"code","colab":{}},"source":["train_data.drop_duplicates(subset=['document'], inplace=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mw80Xsy8xlHs","colab_type":"code","colab":{}},"source":["train_data['label'].value_counts().plot(kind = 'bar')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"za5keGp8yJzp","colab_type":"code","colab":{}},"source":["print(train_data.groupby('label').size().reset_index(name = 'count'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WjOedRbNygdT","colab_type":"code","colab":{}},"source":["print(train_data.isnull().values.any())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QMZsz0sJymvN","colab_type":"code","colab":{}},"source":["print(train_data.isnull().sum())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NFUTGJEOyrYp","colab_type":"code","colab":{}},"source":["train_data.loc[train_data.document.isnull()]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"onu6hktYyveq","colab_type":"code","colab":{}},"source":["train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n","print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-ltOGaLy4Hz","colab_type":"code","colab":{}},"source":["print(len(train_data))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XsU3WAaHy7PU","colab_type":"code","colab":{}},"source":["train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zckn36Y-zKKz","colab_type":"code","colab":{}},"source":["train_data[:5]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fP6wH-fbzRqU","colab_type":"code","colab":{}},"source":["train_data['document'].replace('', np.nan, inplace=True)\n","print(train_data.isnull().sum())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g1k3i3yBzfbk","colab_type":"code","colab":{}},"source":["train_data.loc[train_data.document.isnull()][:5]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ASE4reMmzjIr","colab_type":"code","colab":{}},"source":["train_data = train_data.dropna(how = 'any')\n","print(len(train_data))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z2uNzV1T0pNW","colab_type":"code","colab":{}},"source":["test_data.drop_duplicates(subset = ['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n","test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n","test_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n","test_data = test_data.dropna(how='any') # Null 값 제거\n","print('전처리 후 테스트용 샘플의 개수 :',len(test_data))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-CH6gZBT02tK","colab_type":"code","colab":{}},"source":["stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B8K361v006rx","colab_type":"code","colab":{}},"source":["okt = Okt()\n","okt.morphs('와 이런 것도 영화라고 차라리 뮤직비디오를 만드는 게 나을 뻔', stem = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e9aCIC0v0_Cw","colab_type":"code","colab":{}},"source":["X_train = []\n","for sentence in train_data['document']:\n","    temp_X = []\n","    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n","    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n","    X_train.append(temp_X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WWODdSyW1ZND","colab_type":"code","colab":{}},"source":["print(X_train[:3])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o-pBvmhs3m2y","colab_type":"code","colab":{}},"source":["X_test = []\n","for sentence in test_data['document']:\n","    temp_X = []\n","    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n","    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n","    X_test.append(temp_X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"28lHPr5l3yfI","colab_type":"code","colab":{}},"source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(X_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sOHcnQ9Z4sSn","colab_type":"code","colab":{}},"source":["print(tokenizer.word_index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XHFvV4AI4v1y","colab_type":"code","colab":{}},"source":["threshold = 3\n","total_cnt = len(tokenizer.word_index) # 단어의 수\n","rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n","total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n","rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TS8jn8AO45xK","colab_type":"code","colab":{}},"source":["for key, value in tokenizer.word_counts.items():\n","    total_freq = total_freq + value\n","\n","    # 단어의 등장 빈도수가 threshold보다 작으면\n","    if(value < threshold):\n","        rare_cnt = rare_cnt + 1\n","        rare_freq = rare_freq + value"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V7o5SfeG5Alp","colab_type":"code","colab":{}},"source":["print('단어 집합(vocabulary)의 크기 :',total_cnt)\n","print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n","print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n","print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"apYBeLpB5Dbw","colab_type":"code","colab":{}},"source":["vocab_size = total_cnt - rare_cnt + 1 # 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거. 0번 패딩 토큰을 고려하여 +1\n","print('단어 집합의 크기 :',vocab_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0fGkFgZW5Nyx","colab_type":"code","colab":{}},"source":["tokenizer = Tokenizer(vocab_size) \n","tokenizer.fit_on_texts(X_train)\n","X_train = tokenizer.texts_to_sequences(X_train)\n","X_test = tokenizer.texts_to_sequences(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g02nNYgX5Q_b","colab_type":"code","colab":{}},"source":["print(X_train[:3])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9dzdSwn5UwY","colab_type":"code","colab":{}},"source":["y_train = np.array(train_data['label'])\n","y_test = np.array(test_data['label'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zTUxzZZp5YFu","colab_type":"code","colab":{}},"source":["drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]\n","drop_test = [index for index, sentence in enumerate(X_test) if len(sentence) < 1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-oE015LQ5a1S","colab_type":"code","colab":{}},"source":["X_train = np.delete(X_train, drop_train, axis=0)\n","y_train = np.delete(y_train, drop_train, axis=0)\n","print(len(X_train))\n","print(len(y_train))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DxwGSnh25hx3","colab_type":"code","colab":{}},"source":["X_test = np.delete(X_test, drop_test, axis=0)\n","y_test = np.delete(y_test, drop_test, axis=0)\n","print(len(X_test))\n","print(len(y_test))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PdliCPzc5mq9","colab_type":"code","colab":{}},"source":["print('리뷰의 최대 길이 :',max(len(l) for l in X_train))\n","print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n","plt.hist([len(s) for s in X_train], bins=50)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Bt0Ivkg5qF6","colab_type":"code","colab":{}},"source":["def below_threshold_len(max_len, nested_list):\n","  cnt = 0\n","  for s in nested_list:\n","    if(len(s) <= max_len):\n","        cnt = cnt + 1\n","  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bTMmddIr6Q6Y","colab_type":"code","colab":{}},"source":["max_len = 30\n","below_threshold_len(max_len, X_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HMQoBcMY6krV","colab_type":"code","colab":{}},"source":["X_train = pad_sequences(X_train, maxlen = max_len)\n","X_test = pad_sequences(X_test, maxlen = max_len)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r42TqT7P6qRW","colab_type":"code","colab":{}},"source":["from tensorflow.keras.layers import Embedding, Dense, LSTM\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bhmFQ4cr6tX9","colab_type":"code","colab":{}},"source":["model = Sequential()\n","model.add(Embedding(vocab_size, 100))\n","model.add(LSTM(128))\n","model.add(Dense(1, activation='sigmoid'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PJjHpOqS6vsv","colab_type":"code","colab":{}},"source":["es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n","mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"90EKXZUX6zSN","colab_type":"code","colab":{}},"source":["model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n","history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=60, validation_split=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7uAdd-YW630W","colab_type":"code","colab":{}},"source":["loaded_model = load_model('best_model.h5')\n","print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7VKWVTCBD1BU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}